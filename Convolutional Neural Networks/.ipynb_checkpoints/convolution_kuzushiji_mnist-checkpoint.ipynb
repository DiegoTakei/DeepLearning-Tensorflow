{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.load('kuzushiji_mnist/'+'kmnist-train-imgs.npz')['arr_0']\n",
    "test_images = np.load('kuzushiji_mnist/'+'kmnist-test-imgs.npz')['arr_0']\n",
    "train_labels = np.load('kuzushiji_mnist/'+'kmnist-train-labels.npz')['arr_0']\n",
    "test_labels = np.load('kuzushiji_mnist/'+'kmnist-test-labels.npz')['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = train_labels.reshape(-1, 1)\n",
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.asarray(train_images, dtype = np.float32)\n",
    "train_labels = np.asarray(train_labels, dtype = np.int32)\n",
    "test_images = np.asarray(test_images, dtype = np.float32)\n",
    "test_labels = np.asarray(test_labels, dtype = np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Classe: [7]')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(train_images[1], cmap = 'gray')\n",
    "plt.title('Classe: ' + str(train_labels[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_df = pd.read_csv('kuzushiji_mnist/'+'kmnist_classmap.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>codepoint</th>\n",
       "      <th>char</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>U+304A</td>\n",
       "      <td>お</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>U+304D</td>\n",
       "      <td>き</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>U+3059</td>\n",
       "      <td>す</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>U+3064</td>\n",
       "      <td>つ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>U+306A</td>\n",
       "      <td>な</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>U+306F</td>\n",
       "      <td>は</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>U+307E</td>\n",
       "      <td>ま</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>U+3084</td>\n",
       "      <td>や</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>U+308C</td>\n",
       "      <td>れ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>U+3092</td>\n",
       "      <td>を</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index codepoint char\n",
       "0      0    U+304A    お\n",
       "1      1    U+304D    き\n",
       "2      2    U+3059    す\n",
       "3      3    U+3064    つ\n",
       "4      4    U+306A    な\n",
       "5      5    U+306F    は\n",
       "6      6    U+307E    ま\n",
       "7      7    U+3084    や\n",
       "8      8    U+308C    れ\n",
       "9      9    U+3092    を"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network(features, labels, mode):\n",
    "    input = tf.reshape(features['x'], [-1, 28, 28, 1])\n",
    "    \n",
    "    # receives [batch_size, 28, 28, 1]\n",
    "    # returns [batch_size, 28, 28, 32]\n",
    "    convolution1 = tf.layers.conv2d(inputs = input, filters = 32, kernel_size = [5,5], activation = tf.nn.relu,\n",
    "                                 padding = 'same')\n",
    "    \n",
    "    # receives [batch_size, 28, 28, 1]\n",
    "    # returns [batch_size, 14, 14, 32]\n",
    "    pooling1 = tf.layers.max_pooling2d(inputs = convolution1, pool_size = [2,2], strides = 2)\n",
    "    \n",
    "    # receives [batch_size, 14, 14, 32]\n",
    "    # returns [batch_size, 14, 14, 64]\n",
    "    convolution2 = tf.layers.conv2d(inputs = pooling1, filters = 64, kernel_size = [5,5], activation = tf.nn.relu,\n",
    "                                  padding = 'same')\n",
    "    \n",
    "    # receives [batch_size, 14, 14, 64]\n",
    "    # returns [batch_size, 7, 7, 64]\n",
    "    pooling2 = tf.layers.max_pooling2d(inputs = convolution2, pool_size = [2,2], strides = 2)\n",
    "    \n",
    "    # receives [batch_size, 7, 7, 64]\n",
    "    # returns [batch_size, 3136]\n",
    "    flattening = tf.reshape(pooling2, [-1, 7 * 7 * 64])\n",
    "    \n",
    "    # 3136 inputs -> 1024 neurons on hidden layer -> 10 outputs\n",
    "    # receives [batch_size, 3136]\n",
    "    # returns [batch_size, 1024]\n",
    "    dense = tf.layers.dense(inputs = flattening, units = 1024, activation = tf.nn.relu)\n",
    "    \n",
    "    # dropout\n",
    "    dropout =  tf.layers.dropout(inputs = dense, rate = 0.2, training = mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    \n",
    "    # receives [batch_size, 1024]\n",
    "    # returns [batch_size, 10]\n",
    "    output = tf.layers.dense(inputs = dropout, units = 10)\n",
    "    \n",
    "    predictions = tf.argmax(output, axis = 1)\n",
    "    \n",
    "    if(mode == tf.estimator.ModeKeys.PREDICT):\n",
    "        return tf.estimator.EstimatorSpec(mode = mode, predictions = predictions)  \n",
    "    \n",
    "    losses = tf.losses.sparse_softmax_cross_entropy(labels = labels, logits = output)\n",
    "    \n",
    "    if(mode == tf.estimator.ModeKeys.TRAIN):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate = 0.001)\n",
    "        train = optimizer.minimize(losses, global_step = tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode = mode, loss = losses, train_op = train)\n",
    "    \n",
    "    if(mode == tf.estimator.ModeKeys.EVAL):\n",
    "        eval_metrics_ops = {'accuracy': tf.metrics.accuracy(labels = labels, predictions = predictions)}\n",
    "        return tf.estimator.EstimatorSpec(mode = mode, loss = losses, eval_metric_ops = eval_metrics_ops)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\diego\\AppData\\Local\\Temp\\tmp0ycbq3h_\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\diego\\\\AppData\\\\Local\\\\Temp\\\\tmp0ycbq3h_', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000274547810F0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "classifier = tf.estimator.Estimator(model_fn = create_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\diego\\AppData\\Local\\Temp\\tmp0ycbq3h_\\model.ckpt-200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 200 into C:\\Users\\diego\\AppData\\Local\\Temp\\tmp0ycbq3h_\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.2098878, step = 201\n",
      "INFO:tensorflow:global_step/sec: 2.03541\n",
      "INFO:tensorflow:loss = 0.23770212, step = 301 (49.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.03503\n",
      "INFO:tensorflow:loss = 0.20763357, step = 401 (49.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.01089\n",
      "INFO:tensorflow:loss = 0.34033582, step = 501 (49.781 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.89078\n",
      "INFO:tensorflow:loss = 0.13038436, step = 601 (52.837 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.87363\n",
      "INFO:tensorflow:loss = 0.081632316, step = 701 (53.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.8568\n",
      "INFO:tensorflow:loss = 0.13824037, step = 801 (53.887 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.83627\n",
      "INFO:tensorflow:loss = 0.064239986, step = 901 (54.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.89814\n",
      "INFO:tensorflow:loss = 0.10208641, step = 1001 (52.703 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.94102\n",
      "INFO:tensorflow:loss = 0.059980825, step = 1101 (51.621 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.97483\n",
      "INFO:tensorflow:loss = 0.04927987, step = 1201 (50.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.89576\n",
      "INFO:tensorflow:loss = 0.020047938, step = 1301 (52.748 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1350 into C:\\Users\\diego\\AppData\\Local\\Temp\\tmp0ycbq3h_\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.6641\n",
      "INFO:tensorflow:loss = 0.04071699, step = 1401 (60.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.86292\n",
      "INFO:tensorflow:loss = 0.024624739, step = 1501 (53.679 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.96647\n",
      "INFO:tensorflow:loss = 0.0074006217, step = 1601 (50.889 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.7632\n",
      "INFO:tensorflow:loss = 0.030589746, step = 1701 (56.679 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.84565\n",
      "INFO:tensorflow:loss = 0.0704405, step = 1801 (54.180 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.97024\n",
      "INFO:tensorflow:loss = 0.015304016, step = 1901 (50.788 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.88974\n",
      "INFO:tensorflow:loss = 0.013517328, step = 2001 (52.885 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.01036\n",
      "INFO:tensorflow:loss = 0.014006453, step = 2101 (49.742 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2200 into C:\\Users\\diego\\AppData\\Local\\Temp\\tmp0ycbq3h_\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.04639273.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x27454711b00>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_function = tf.estimator.inputs.numpy_input_fn(x = {'x': train_images}, y = train_labels, \n",
    "                                                        batch_size= 128, num_epochs= None, shuffle= True)\n",
    "classifier.train(input_fn = train_function, steps = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-01-18-12:04:03\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\diego\\AppData\\Local\\Temp\\tmp0ycbq3h_\\model.ckpt-2200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-01-18-12:04:17\n",
      "INFO:tensorflow:Saving dict for global step 2200: accuracy = 0.9303, global_step = 2200, loss = 0.3273471\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2200: C:\\Users\\diego\\AppData\\Local\\Temp\\tmp0ycbq3h_\\model.ckpt-2200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9303, 'loss': 0.3273471, 'global_step': 2200}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_function = tf.estimator.inputs.numpy_input_fn(x = {'x': test_images}, y = test_labels, num_epochs = 1, shuffle = False)\n",
    "\n",
    "results = classifier.evaluate(input_fn = test_function)\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
